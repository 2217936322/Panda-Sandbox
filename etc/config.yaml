###########################################################
#                  Panda Sandbox(钟馗沙箱)                  #
###########################################################
#
# Sandbox Release Version
version: 1.0.0-alpha


# Sandbox Common Settings
settings:
  ## The running mode of the sandbox to filter file
  ## 4: Cluster mode
  ## 3: Verify mode
  ## 2: Sandbox mode
  ## 1: Live mode
  mode: 1
  #################### cluster mode ###################
  master: False
  server: 172.16.12.1
  ## Enable creation of memory dump of the analysis machine before shutting
  ## down. Even if turned off, this functionality can also be enabled at
  ## submission. Currently available for: VirtualBox and libvirt modules (KVM).
  memory_dump: False
  ## To enable the procmon analyser running in the machine.
  procmon_dump: False
  ## The file operations by the malware in the machine.
  dropped_files: True
  ## When the timeout of an analysis is hit, the VM is just killed by default.
  ## For some long-running setups it might be interesting to terminate the
  ## monitored processes before killing the VM so that connections are closed.
  terminate_processes: False
  ## The platform of file support by sandbox, inspector depends on this to determine whether
  ## to store this task in sandbox workflow, by default if it turn on the task will put into
  ## queue in workflow, with no consumer it will block the inspector thread.
  support:
    linux:
      enable: False
      extension:
        - 'crx'
        - 'htm'
        - 'txt'
    darwin:
      enable: False
      extension:
        - 'mac'
    android:
      enable: False
      extension:
        - 'apk'
        - 'dex'
    archive:
      enable: True
      extension:
        - '7z'
        - 'lzh'
        - 'rar'
        - 'zip'
        - 'eml'
        - 'msg'
        - 'ace'
        - 'cab'
        - 'bzip'
        - 'gzip'
    browser:
      enable: True
      extension:
        - 'shell'
        - 'elf'
        - 'deb'
        - 'rpm'
        - 'kernel'
        - 'perl'
    windows:
      enable: True
      extension:
        - 'js'
        - 'exe'
        - 'doc'
        - 'xls'
        - 'ppt'
        - 'pdf'
        - 'msi'
        - 'rtf'
        - 'ps1'
        - 'inf'
        - 'zip'
        - 'tar'
        - 'jar'
        - 'dll'
        - 'bin'
        - 'lnk'
        - 'bat'
        - 'cmd'
        - 'com'
        - 'cpl'
        - 'dos'
        - 'emf'
        - 'gif'
        - 'hlp'
        - 'img'
        - 'jpg'
        - 'png'
        - 'psi'
        - 'swf'
        - 'sys'
        - 'vbs'
        - 'wps'
        - 'wsf'
        - 'xar'
        - 'xml'
        - 'pptx'
        - 'xlsx'
        - 'docx'
        - 'exe+'
        - 'pcap'
        - 'audio'
        - 'video'
        - 'python'
        - 'generic'


# Sandbox Logging Settings
logging:
  version: 1
  disable_existing_loggers: False
  formatters:
    simple:
      format: "%(asctime)s | %(levelname)s | %(message)s"
    detail:
      format: "%(asctime)s-[%(filename)s:%(lineno)s-%(levelname)s]: %(message)s"
  handlers:
    console:
      class: "lib.panda.plugins.logger.ConsoleHandler.ConsoleHandler"
      level: DEBUG
      formatter: detail
      stream: ext://sys.stdout
    sandbox:
      class: logging.FileHandler
      level: INFO
      formatter: detail
      filename: "/data1/logs/cluster/panda.log"
    backend:
      class: logging.FileHandler
      level: DEBUG
      formatter: detail
      filename: "/data1/logs/cluster/backend.log"
    libvirt:
      class: logging.FileHandler
      level: ERROR
      formatter: detail
      filename: "/data1/logs/cluster/libvirt.log"
    distribute:
      class: logging.FileHandler
      level: DEBUG
      formatter: detail
      filename: "/data1/logs/cluster/distribute.log"
  loggers:
    sandbox:
      level: INFO
      handlers: [sandbox]
      propagate: False
    backend:
      level: INFO
      handlers: [backend]
      propagate: False
    libvirt:
      level: ERROR
      handlers: [libvirt]
      propagate: False
    distribute:
      level: DEBUG
      handlers: [distribute]
      propagate: False
  roots:
    level: ERROR
    handlers: []


# Sandbox Storage Settings
storage:
  ## The middle result and file storage path. Need High I/O of disk.
  temporary: "/data0"
  ## The final report storage path. Need the huge size of disk.
  persistent: "/data1"
  ## The file store in which file system of the machine. By default its the local file system,
  ## but for the distribute we suggest it to be mongo gridfs to store analysis file and results.
  ## LFS: local file system
  ## GridFS: mongo-grid file system
  fs: LFS
  ## The extract file path by receiver message from redis
  ## extract_path: "/data1/bds_extracted_files"
  schedule:
    ### Minimum amount of free space (in %) available before starting a new task.
    ### This tries to avoid failing an analysis because the reports can't be written
    ### due out-of-disk-space errors. Setting this value to 0 disables the check.
    ### (Note: this feature is currently not supported under Windows.)
    disk-space: 0.3
    ### The clean left data by day schedule 3 month
    store-days: 90
    ### The one time to delete the task number, to make sure the storage data not be full.
    delete-number: 10
  delete:
    temp_files: True
    origin_file: True


# Sandbox Backend Settings
backend:
  async:
    enable: True
    mode: TCPSocket
    host: "127.0.0.1"
    port: 7706
  # This config it to display to readers for where the backend start mode and server path, not inflect the code.
  bloom:
    enable: True
    mode: LocalSocket
    path: socket/bloom.sock
  intel:
    enable: True
    mode: LocalSocket
    path: socket/intel.sock
  # This config it to display to readers for where the backend start mode and server path, not inflect the code.
  matrix:
    enable: True
    mode: LocalSocket
    path: socket/matrix.sock
  ## The Sandbox to receive the file path from local by restful communicate.
  restful:
    enable: True
    mode: TCPSocket
    host: "127.0.0.1"
    port: 9377
  ## The Sandbox to receive the file path from local by socket communicate.
  service:
    enable: True
    mode: TCPSocket
    host: "127.0.0.1"
    port: 62042


# Sandbox Database Settings
database:
  mysql:
    ## The default database provide service host
    host: "localhost"
    ## The default database provide service port
    port: 3306
    ## Database connection timeout in seconds.
    ## If empty, default is set to 60 seconds.
    timeout: 60
    ## The connect database name.
    dbname: "sandbox"
    ## The username of the database to auth.
    username: "root"
    ## The password of the database to auth.
    password: "it's so secret!"
    ## Specify the database connection string.
    ## Examples, see documentation for more:
    driver: mysqlconnector

  mongodb:
    ## The default database provide service host
    host: "localhost"
    ## The default database provide service port
    port: 27017
    ## The connect database name.
    dbname: "panda"
    ## The username of the database to auth.
    username: "root"
    ## The password of the database to auth.
    password: "it's so secret!"
    ## Automatically delete large dict values that exceed mongos 16MB limitation
    ## Note: This only deletes dict keys from data stored in MongoDB. You would
    ## still get the full dataset if you parsed the results dict in another
    ## reporting module or from the jsondump module.
    fix_large_docs: True

  redis:
    ## The default database provide service host
    host: "localhost"
    ## The default database provide service port
    port: 6379
    ## The sandbox channel for manage tasks status in different stage.
    channel:
      extract: "filextract"
      tasks: "sandbox-tasks"
      report: "sandbox-report"
      publish: "sandbox-publish"
      event: "sandbox-event"
      notice: "awesome_notice"

  elasticsearch:
    ## The default database provide service host
    host: "elasticsearch"
    ## The default database provide service port
    port: 9200
    # Elasticsearch connection timeout in seconds.
    timeout: 60
    ## The auth of the elasticsearch index search.
    cert: ""
    ## The default sandbox index name.
    indices:
      ai:
        enable: True
        index: "sandbox-matrix"
      event:
        enable: True
        index: "sandbox-event"
      analysis:
        enable: True
        index: "sandbox-analysis"


# Sandbox Machine Settings
machine:
  ## The machine snapshot settings method.
  ## save: Provide external image save of machine.
  ## snapshot: Provide the snapshot of machine.
  snapshot: save
  ## The machine image settings
  storage:
    ### The image storage path
    path: "/data0"
    ### The external vm snapshot folder name.
    snapshot: "vm_stat"
  ## The vcpu set of the machine to binding with and the every node of the machine to spend number of the vcpu.
  kernel:
    vcpu: []
    binds: 4
  ## The timeouts of the machine running status.
  timeouts:
    ### Set the default analysis timeout expressed in seconds. This value will be
    ### used to define after how many seconds the analysis will terminate unless
    ### otherwise specified at submission.
    default: 60
    ### Set the critical timeout expressed in (relative!) seconds. It will be added
    ### to the default timeout above and after this timeout is hit
    ### Cuckoo will consider the analysis failed and it will shutdown the machine
    ### no matter what. When this happens the analysis results will most likely
    ### be lost.
    critical: 60
    ### Maximum time to wait for virtual machine status change. For example when
    ### shutting down a vm. Default is 30 seconds.
    vm_state: 60
  resultserver:
    host: "192.168.122.1"
    port: 2042
    ### Maximum size and Minimum size of uploaded files from VM (screenshots, dropped files, log)
    ### The value is expressed in bytes, by default 40Mb
    upload_min_size: 512
    upload_max_size: 41943040
  ## The virtual machine platform settings.
  platform:
    ### name: The images of virtual machines name.
    ### count: The number of the each platform.
    windows:
      name: "windows.qcow2"
      count: 1
    android:
      name: "android.qcow2"
      count: 0
    darwin:
      name: "darwin.qcow2"
      count: 0
    linux:
      name: "linux.qcow2"
      count: 0


# Sandbox Workers Settings
# The section name of the worker is the sub module process name.
# The enable is the status of the worker to start or not.
# The status is the Brain manager to check the worker is alive or not cycle time.
workers:
  ## 接收待检测文件的子模块，两种模式: Redis 模式 & Router 模式.
  ## > Redis 模式负责接收从引擎还原出来的文件，Router 模式负责作为集群模式中子节点接收父节点的文件.
  ## > 该功能模块会根据配置的单机结点数量创建相应的线程进行文件的接收
  Receiver:
    enable: True
    status: 5
    pending: 20000  # 最大的数据库排队数量，多余该数量的待检测文件，将进行丢弃，如果设置为 0 则对应无限制
    limit:  # 对于检测文件的大小限制
      upsize: 4194304
      downsize: 49152
  ## 提供待检测文件的子模块，两种模式：Single 模式 & Router 模式，两种通道：将待检测的文件和待出报告的文件输出到相应的 redis 通道.
  ## > Single 模式负责本地的调用，将本地的 DB 数据查询输出，Router 模式负责集群模式中父节点进行分发文件的任务.
  ## > tasks 对应的通道是输送文件对象到 Inspector 中去虚拟机中检测，report 对应的通道是输送检测完的文件对象到 Processor 中分析对应的动态行为
  Provider:
    enable: True
    status: 10
  ## 将待检测文件进行过滤(选择对应的虚拟机平台及其他愚蠢的需求)的子模块，三种模式：Default 模式 & Sandbox 模式 & Verify 模式(APT).
  ## > Default 模式负责线上模式的过滤动作，只将部分可能为恶意的文件提交到后续流程，大部分白文件只输出原始事件
  ## > Sandbox 模式负责纯检测模式，只对文件进行虚拟机平台的选择
  ## > Verify 模式负责未知检测模式，最对无法判断是否为恶意的文件提交到后续流程，大部分白文件将落入后续流程
  Inspector:
    enable: True
    status: 300
  ## 专门用来处理，当用户打开 html 等 web 文件类型的时候，高峰值文件涌入沙箱时，沙箱无法处理过来大批量文件的问题，用来泄洪.
  ## > 目前只是使用了 clamav 作为检测的唯一手段，建议通过压测之后，根据效果集成其他检测手段.
  ## > TODO：长远看来，希望在这个地方能够真正集成 web 检测的 sandbox，做到真正的检测相应文件的真沙箱
  Browser:
    enable: True
    status: 5
  ## 专门用来处理，流量中产生的压缩文件，因为压缩文件对沙箱的分析不是十分友好，所以需要对其在宿主机上进行解压，但这个操作并不是十分安全.
  ## > 目前是根据下方配置的 extension 来判断是否需要进行相应分析的，后续需要进行更为有效的判断.
  ## > 后续能够针对于客户手动提交的文件，手动设置解压缩的密码，(后续可以根据av扫描的结果来过滤部分解压动作，提高性能)
  Unpacker:
    enable: True
    status: 300
    extension:
      - "exe"
      - "exe+"
      - "doc"
      - "docx"
      - "xls"
      - "xlsx"
      - "ppt"
      - "pptx"
      - "pdf"
      - "msi"
      - "rtf"
      - "python"
      - "ps1"
      - "inf"
      - "rar"
      - "zip"
      - "7z"
      - "tar"
      - "gzip"
      - "jar"
      - "dll"
      - "bin"
      - "lnk"
  ## 专门用来调度虚拟机的子模块，根据虚拟机的平台信息，分配不同的虚拟机平台(android, windows, linux, darwin)
  ## > 目前只保留了调度 KVM 的内核的虚拟机模块，主要原因是绑定了使用 libvirt 作为管理工具的调度
  ## > 目前使用的是 qemu-kvm 作为虚拟机，相关的配置项都保存在 machine 配置段内，具体请参考其配置
  Analyser:
    enable: True
    status: 30
  ## 这部分子模块不仅仅用来分析虚拟机输出的日志信息，还包括全部的沙箱检测手段，所谓集成沙箱检测手段，都是指在该模块中集成一个 python 脚本即可.
  ## > 包括：process、signature、reporting 三个部分
  ## > 这里是整个框架中最特殊的一部分，因为这里的多进程中的线程不是持续运行的，而是一个文件一个有限线程，运行完后自行退出，所以是整个项目中最奇怪的部分.
  ## > 之所以这么做的原因是，能够限制每个任务在分析过程中的内存使用和 CPU 使用，否则，我们无法对其进行有效停止，最终造成系统的不够稳定.
  ## > TODO: 后续需要集成检测手段，在不考虑整个架构重构的情况下，只需要在这里集成一个脚本即可，注意一定要符合原来的编码规范！！！
  Processor:
    enable: True
    status: 2
    limit:
      time: 600
      memory: 2097152
    level: 1
    delete_bson: True
    delete_drop: True
    rsync_files: False
  ## 这是沙箱中的发送时间的子模块，目前支持在集群（特指在机器学习集群下）和普通模式下的时间输出，这里是文件的总出口，可以对此进行细致的更改.
  ## > 在默认模式下，即普通模式下，输出事件到 redis 中间，然后目前是输出两种数据格式，一种是 event(sandbox-file-event) 一种是 notice(host-threat)
  ## > 只有在集群模式下，才需要将下面的输出改成 elasticsearch，这样沙箱将不会通过 redis 直接向索引中吐出数据.
  Publisher:
    enable: True
    status: 300
    method:
      redis: True
      elasticsearch: False
    message:
      event: True
      notice: True
    delete_database: True
  ## 清理进程，限制沙箱的数据堆积和分析报告的无限增长，因为大部分使用了 shell 脚本进行处理，所以木有开启，不过建议后续启用
  ## TODO: 完善此部分的代码，去除 shell 脚本，保证项目的完整性，对应的属性配置目前在 storage 配置段中.
  Sweeper:
    enable: False
    status: 300

# Sandbox File Caching Settings
caching:
  exe: True
  doc: True
  ppt: True
  xls: True
  rtf: True
  txt: True
  pdf: True
  hta: True
  swf: True
